import os
import openai
import logging
import datetime
from typing import Optional, Dict, Any, List
import json
import time
from datetime import datetime
# os.environ["OPENAI_API_KEY"] = "sk-Pth1hQVprCzicKWmB16396007fC44c568a74F3C8Fb484979"
# os.environ["OPENAI_API_KEY"] = "sk-d1X7CZ7Vs3HwELwY9101927aF49e495bA32a94C8B0337210"

openai.base_url = "http://127.0.0.1:8888/v1/"
# openai.default_headers = {"x-foo": "true"}
openai.default_headers={
                "Connection": "close",  # é¿å…ä¿æŒè¿æ¥
                "Keep-Alive": "timeout=0"  # ç¦ç”¨keep-alive
            }
class OpenAIAPI:
    """
    OpenAI APIå°è£…ç±»
    
    æä¾›ç®€å•æ˜“ç”¨çš„æ¥å£æ¥è°ƒç”¨OpenAIæ¨¡å‹
    """
    
    def __init__(
        self,
        key: str,
        base_url: str = openai.base_url,
        default_headers: Dict[str, str] = openai.default_headers,
        debug: bool = False,
        debug_dir: str = "Debug"
    ):
        """
        åˆå§‹åŒ–OpenAI APIå®¢æˆ·ç«¯
        
        Args:
            base_url (str): APIåŸºç¡€URL
            default_headers (dict): é»˜è®¤è¯·æ±‚å¤´
            debug (bool): æ˜¯å¦å¯ç”¨debugæ¨¡å¼
            debug_dir (str): debugæ—¥å¿—ä¿å­˜ç›®å½•
        """
        openai.api_key = key
        openai.base_url = base_url
        openai.default_headers = default_headers
        
        self.debug = debug
        self.debug_dir = debug_dir
        
        if self.debug:
            self._setup_debug_logging()
    
    def _setup_debug_logging(self):
        """è®¾ç½®debugæ—¥å¿—"""
        # ç¡®ä¿Debugæ–‡ä»¶å¤¹å­˜åœ¨
        if not os.path.exists(self.debug_dir):
            os.makedirs(self.debug_dir)
        
        # åˆ›å»ºlogger
        self.logger = logging.getLogger('OpenAIAPI')
        self.logger.setLevel(logging.DEBUG)
        
        # é¿å…é‡å¤æ·»åŠ handler
        if not self.logger.handlers:
            # åˆ›å»ºæ–‡ä»¶handler
            debug_filename = os.path.join(
                self.debug_dir, 
                f"openai_api_debug_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
            )
            file_handler = logging.FileHandler(debug_filename, encoding='utf-8')
            file_handler.setLevel(logging.DEBUG)
            
            # åˆ›å»ºæ§åˆ¶å°handler
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            
            # åˆ›å»ºformatter
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(formatter)
            console_handler.setFormatter(formatter)
            
            # æ·»åŠ handleråˆ°logger
            self.logger.addHandler(file_handler)
            self.logger.addHandler(console_handler)
            
            self.logger.info(f"ğŸ”§ OpenAI API Debugæ¨¡å¼å·²å¯ç”¨ï¼Œæ—¥å¿—ä¿å­˜åˆ°: {debug_filename}")
    
    def _log_request(self, model: str, content: str, **kwargs):
        """è®°å½•APIè¯·æ±‚ä¿¡æ¯"""
        if self.debug:
            self.logger.debug("=" * 50)
            self.logger.debug("ğŸ“¤ APIè¯·æ±‚ä¿¡æ¯:")
            self.logger.debug(f"Model: {model}")
            self.logger.debug(f"Content length: {len(content)} chars")
            self.logger.debug(f"Content preview: {content[:200]}...")
            self.logger.debug(f"Temperature: {kwargs.get('temperature', 'N/A')}")
            self.logger.debug(f"Max tokens: {kwargs.get('max_tokens', 'N/A')}")
            self.logger.debug("=" * 50)
    
    def _log_response(self, response: Dict[str, Any], duration: float):
        """è®°å½•APIå“åº”ä¿¡æ¯"""
        if self.debug:
            self.logger.debug("ğŸ“¥ APIå“åº”ä¿¡æ¯:")
            self.logger.debug(f"è€—æ—¶: {duration:.2f}ç§’")
            self.logger.debug(f"Model: {response.get('model', 'N/A')}")
            self.logger.debug(f"ID: {response.get('id', 'N/A')}")
            self.logger.debug(f"Finish reason: {response.get('finish_reason', 'N/A')}")
            
            if 'usage' in response:
                usage = response['usage']
                self.logger.debug(f"Tokenä½¿ç”¨æƒ…å†µ:")
                self.logger.debug(f"  - Prompt tokens: {usage.get('prompt_tokens', 0)}")
                self.logger.debug(f"  - Completion tokens: {usage.get('completion_tokens', 0)}")
                self.logger.debug(f"  - Total tokens: {usage.get('total_tokens', 0)}")
            
            content = response.get('content', '')
            self.logger.debug(f"Response length: {len(content)} chars")
            self.logger.debug(f"Response preview: {content[:200]}...")
            self.logger.debug("=" * 50)
    
    def _log_error(self, error: Exception, model: str, content_length: int):
        """è®°å½•APIé”™è¯¯ä¿¡æ¯"""
        if self.debug:
            self.logger.error("âŒ APIè°ƒç”¨å¤±è´¥:")
            self.logger.error(f"Model: {model}")
            self.logger.error(f"Content length: {content_length}")
            self.logger.error(f"Error: {str(error)}")
            self.logger.error("=" * 50)
    
    def chat_completion(
        self, 
        content: str, 
        model: str,
        role: str = "user",
        temperature: float = 0.0,
        max_tokens: Optional[int] = 8192,
    ) -> str:
        """
        è°ƒç”¨èŠå¤©å®ŒæˆAPI
        
        Args:
            content (str): ç”¨æˆ·è¾“å…¥å†…å®¹
            model (str): æ¨¡å‹åç§°ï¼ˆå¿…å¡«ï¼‰
            role (str): æ¶ˆæ¯è§’è‰²ï¼Œé»˜è®¤ä¸ºuser
            temperature (float): æ¸©åº¦å‚æ•°ï¼Œ0.0æœ€ç¡®å®šï¼Œ1.0æœ€æœ‰åˆ›æ„
            max_tokens (int): æœ€å¤§tokenæ•°é‡
            
        Returns:
            str: AIçš„å›å¤å†…å®¹
            
        Raises:
            Exception: APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        import time
        start_time = time.time()
        
        self._log_request(model, content, temperature=temperature, max_tokens=max_tokens)
        
        try:
            completion = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": role, "content": content}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                skip_special_tokens=True
            )
            
            duration = time.time() - start_time
            
            # æ„å»ºå“åº”ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•
            response_info = {
                "content": completion.choices[0].message.content,
                "model": completion.model,
                "id": completion.id,
                "finish_reason": completion.choices[0].finish_reason,
                "usage": {
                    "prompt_tokens": completion.usage.prompt_tokens,
                    "completion_tokens": completion.usage.completion_tokens,
                    "total_tokens": completion.usage.total_tokens
                }
            }
            
            self._log_response(response_info, duration)
            
            return completion.choices[0].message
        except Exception as e:
            self._log_error(e, model, len(content))
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    
    def get_response(self, model: str, prompt: str, api_log_path: str, max_tokens: int = 20480) -> Dict[str, Any]:
        """
        è·å–å›å¤å’Œtokensä½¿ç”¨ä¿¡æ¯ï¼Œå¹¶ä¿å­˜è¯¦ç»†æ—¥å¿—
        
        Args:
            model (str): æ¨¡å‹åç§°
            prompt (str): ç”¨æˆ·è¾“å…¥å†…å®¹
            api_log_path (str): APIè°ƒç”¨æ—¥å¿—ä¿å­˜è·¯å¾„
            
        Returns:
            dict: åŒ…å«å›å¤å†…å®¹å’Œtokensä½¿ç”¨ä¿¡æ¯
        """
        start_time = time.time()
        # prompt += "Do not output the thought process; provide the answer directly.\n"
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(api_log_path), exist_ok=True)
        
        # å‡†å¤‡æ—¥å¿—å†…å®¹
        log_entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "model": model,
            "prompt": prompt,
            "request": {
                "temperature": 0.0,
                "max_tokens": max_tokens
            }
        }
        
        try:
            # APIä¼šè‡ªåŠ¨è¿”å›tokenæ•°é‡ï¼Œä¸éœ€è¦æœ¬åœ°è®¡ç®—
            
            # åˆ›å»ºæ™®é€šå“åº”è€Œä¸æ˜¯æµå¼å“åº”
            completion = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=max_tokens
            )
            
            # ç›´æ¥ä»å“åº”ä¸­è·å–å†…å®¹
            complete_response = completion.choices[0].message.content
            finish_reason = completion.choices[0].finish_reason
            response_id = completion.id
            
            # ä½¿ç”¨APIè¿”å›çš„tokenæ•°é‡
            
            duration = time.time() - start_time
            
            response = {
                "content": complete_response,
                "role": "assistant",
                "finish_reason": finish_reason,
                "usage": {
                    "prompt_tokens": completion.usage.prompt_tokens,
                    "completion_tokens": completion.usage.completion_tokens,
                    "total_tokens": completion.usage.total_tokens
                },
                "model": model,
                "id": response_id,
                "duration": duration
            }
            
            # æ›´æ–°æ—¥å¿—å†…å®¹
            log_entry.update({
                "response": response,
                "duration": f"{duration:.2f}ç§’",
                "status": "success"
            })
            
        except Exception as e:
            error_msg = str(e)
            if self.debug:
                self._log_error(e, model, len(prompt))
            
            # è®°å½•é”™è¯¯ä¿¡æ¯åˆ°æ—¥å¿—
            log_entry.update({
                "status": "error",
                "error": error_msg,
                "duration": f"{time.time() - start_time:.2f}ç§’"
            })
            
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {error_msg}")
        
        finally:
            # å°†æ—¥å¿—å†™å…¥æ–‡ä»¶
            try:
                with open(api_log_path, 'a', encoding='utf-8') as f:
                    json.dump(log_entry, f, ensure_ascii=False, indent=2)
                    f.write('\n')  # æ¯ä¸ªæ—¥å¿—æ¡ç›®åæ·»åŠ æ¢è¡Œ
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ— æ³•å†™å…¥APIæ—¥å¿—åˆ°{api_log_path}: {str(e)}")
        
        return response

# ä½¿ç”¨ç¤ºä¾‹
# if __name__ == "__main__":
#     try:
#         # å¯ç”¨debugæ¨¡å¼
#         api = OpenAIAPI(debug=True)
        
#         # æ–¹æ³•1ï¼šåªè·å–æ–‡æœ¬å†…å®¹
#         response1 = api.get_response(model="deepseek-r1-250528", prompt="Hello world!")
#         print(response1)
#         print(response1["content"])

        
#     except Exception as e:
#         print(f"é”™è¯¯: {e}")
        
        